{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN for Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, Flatten, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-22 15:35:00.022888: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Initializing the CNN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Convolution Layer\n",
    "classifier.add(Convolution2D(32, (3, 3), input_shape=(32, 32, 3), activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Pooling Layer\n",
    "classifier.add(MaxPooling2D(pool_size=(2, 2)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flattening the layer\n",
    "classifier.add(Flatten())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the Fully Connected layer\n",
    "classifier.add(Dense(units=128, activation='relu'))  # Hidden layer\n",
    "classifier.add(Dense(units=1, activation='sigmoid'))  # Output layer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the CNN\n",
    "classifier.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 800 validated image filenames belonging to 2 classes.\n",
      "Found 200 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/keras/preprocessing/image.py:1137: UserWarning: Found 200 invalid image filename(s) in x_col=\"isic_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.10/site-packages/keras/preprocessing/image.py:1137: UserWarning: Found 800 invalid image filename(s) in x_col=\"isic_id\". These filename(s) will be ignored.\n",
      "  warnings.warn(\n",
      "/var/folders/gy/sq_b71qx3931n7lpgb669l0w0000gq/T/ipykernel_21572/2220612322.py:57: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  classifier.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.6356 - accuracy: 0.7550 - val_loss: 0.3897 - val_accuracy: 0.8800\n",
      "Epoch 2/25\n",
      "25/25 [==============================] - 70s 3s/step - loss: 0.5162 - accuracy: 0.7763 - val_loss: 0.3811 - val_accuracy: 0.8800\n",
      "Epoch 3/25\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.5066 - accuracy: 0.7862 - val_loss: 0.3951 - val_accuracy: 0.8800\n",
      "Epoch 4/25\n",
      "25/25 [==============================] - 75s 3s/step - loss: 0.4882 - accuracy: 0.7950 - val_loss: 0.5015 - val_accuracy: 0.8700\n",
      "Epoch 5/25\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.4994 - accuracy: 0.7937 - val_loss: 0.3928 - val_accuracy: 0.8750\n",
      "Epoch 6/25\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.4713 - accuracy: 0.8025 - val_loss: 0.4231 - val_accuracy: 0.8800\n",
      "Epoch 7/25\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.4805 - accuracy: 0.8075 - val_loss: 0.4320 - val_accuracy: 0.8650\n",
      "Epoch 8/25\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.4668 - accuracy: 0.8112 - val_loss: 0.3949 - val_accuracy: 0.8750\n",
      "Epoch 9/25\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.4691 - accuracy: 0.8050 - val_loss: 0.3615 - val_accuracy: 0.8800\n",
      "Epoch 10/25\n",
      "25/25 [==============================] - 65s 3s/step - loss: 0.4602 - accuracy: 0.8112 - val_loss: 0.3825 - val_accuracy: 0.8800\n",
      "Epoch 11/25\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.4573 - accuracy: 0.8037 - val_loss: 0.5012 - val_accuracy: 0.8100\n",
      "Epoch 12/25\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.4595 - accuracy: 0.8125 - val_loss: 0.3865 - val_accuracy: 0.8700\n",
      "Epoch 13/25\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.4578 - accuracy: 0.8100 - val_loss: 0.3691 - val_accuracy: 0.8800\n",
      "Epoch 14/25\n",
      "25/25 [==============================] - 73s 3s/step - loss: 0.4466 - accuracy: 0.8100 - val_loss: 0.3930 - val_accuracy: 0.8650\n",
      "Epoch 15/25\n",
      "25/25 [==============================] - 71s 3s/step - loss: 0.4551 - accuracy: 0.8075 - val_loss: 0.4220 - val_accuracy: 0.8600\n",
      "Epoch 16/25\n",
      "25/25 [==============================] - 70s 3s/step - loss: 0.4472 - accuracy: 0.8112 - val_loss: 0.4393 - val_accuracy: 0.8450\n",
      "Epoch 17/25\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.4420 - accuracy: 0.8163 - val_loss: 0.3738 - val_accuracy: 0.8800\n",
      "Epoch 18/25\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.4373 - accuracy: 0.8225 - val_loss: 0.3686 - val_accuracy: 0.8800\n",
      "Epoch 19/25\n",
      "25/25 [==============================] - 65s 3s/step - loss: 0.4457 - accuracy: 0.8100 - val_loss: 0.3667 - val_accuracy: 0.8850\n",
      "Epoch 20/25\n",
      "25/25 [==============================] - 67s 3s/step - loss: 0.4377 - accuracy: 0.8112 - val_loss: 0.4757 - val_accuracy: 0.8250\n",
      "Epoch 21/25\n",
      "25/25 [==============================] - 74s 3s/step - loss: 0.4469 - accuracy: 0.8050 - val_loss: 0.4321 - val_accuracy: 0.8400\n",
      "Epoch 22/25\n",
      "25/25 [==============================] - 70s 3s/step - loss: 0.4374 - accuracy: 0.8150 - val_loss: 0.4586 - val_accuracy: 0.8100\n",
      "Epoch 23/25\n",
      "25/25 [==============================] - 65s 3s/step - loss: 0.4176 - accuracy: 0.8275 - val_loss: 0.3541 - val_accuracy: 0.8850\n",
      "Epoch 24/25\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.4337 - accuracy: 0.8125 - val_loss: 0.3750 - val_accuracy: 0.8800\n",
      "Epoch 25/25\n",
      "25/25 [==============================] - 66s 3s/step - loss: 0.4275 - accuracy: 0.8188 - val_loss: 0.3692 - val_accuracy: 0.8850\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x164471d20>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Load the metadata CSV file and encode the labels\n",
    "metadata_path = '../DATA/metadata.csv'\n",
    "metadata = pd.read_csv(metadata_path)\n",
    "\n",
    "# Make sure the 'isic_id' column contains the full filename with extension, e.g., 'ISIC_0000000.jpg'\n",
    "# Assuming your image files are in .jpg format\n",
    "metadata['isic_id'] = metadata['isic_id'].apply(lambda x: x + '.jpg')\n",
    "\n",
    "# Encode the 'benign_malignant' labels to numerical values\n",
    "le = LabelEncoder()\n",
    "metadata['label'] = le.fit_transform(metadata['benign_malignant'])\n",
    "# Convert the numerical labels to strings as required by flow_from_dataframe for binary classification\n",
    "metadata['label'] = metadata['label'].astype(str)\n",
    "\n",
    "# Define the paths for the training and testing sets\n",
    "train_set_path = '../DATA/ISIC-images/Train'\n",
    "test_set_path = '../DATA/ISIC-images/Test'\n",
    "\n",
    "# Create the ImageDataGenerator for data augmentation and rescaling\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Use flow_from_dataframe to load images and labels based on the dataframe\n",
    "training_set = train_datagen.flow_from_dataframe(\n",
    "    dataframe=metadata,\n",
    "    directory=train_set_path,\n",
    "    x_col='isic_id',  # Column in dataframe that contains the filenames\n",
    "    y_col='label',  # Column in dataframe that contains the labels\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'  # Use 'binary' or 'categorical' based on the problem\n",
    ")\n",
    "\n",
    "test_set = test_datagen.flow_from_dataframe(\n",
    "    dataframe=metadata,\n",
    "    directory=test_set_path,\n",
    "    x_col='isic_id',\n",
    "    y_col='label',\n",
    "    target_size=(32, 32),\n",
    "    batch_size=32,\n",
    "    class_mode='binary'\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model to the training set\n",
    "classifier.fit_generator(\n",
    "    training_set,\n",
    "    steps_per_epoch=len(training_set),\n",
    "    epochs=25,\n",
    "    validation_data=test_set,\n",
    "    validation_steps=len(test_set)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the model\n",
    "classifier.save('../OUTPUT/classifier_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
